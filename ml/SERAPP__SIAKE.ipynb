{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWH_tr0rGTiT"
      },
      "source": [
        "# Projet SER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfqaoNRXGMwe"
      },
      "outputs": [],
      "source": [
        "!pip install numpy pandas scikit-learn\n",
        "!pip install librosa\n",
        "!pip install mrmr-selection\n",
        "!pip install soundfile\n",
        "!pip install librosa\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bTdm2BlGMwg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, confusion_matrix, classification_report, precision_score, recall_score\n",
        "#from pymrmr import mRMR\n",
        "import librosa\n",
        "#from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy.signal import find_peaks\n",
        "import soundfile as sf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "#from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2EqIjw1GPC0"
      },
      "source": [
        "## Data Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lVE6sy4IKaM"
      },
      "source": [
        "### From local path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlKDnjZsGMwg"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "def collect_data_ravdess(audio_path):\n",
        "    data = pd.DataFrame()\n",
        "\n",
        "    for file in os.listdir(audio_path):\n",
        "        if file.endswith(\".wav\"):\n",
        "            filepath = os.path.join(audio_path, file)\n",
        "            label = file.split(\"-\")[2]  # Extracting emotion label from filename\n",
        "\n",
        "            # Append the filepath and label to the DataFrame\n",
        "            data = data.append({\"filepath\": filepath, \"label\": label}, ignore_index=True)\n",
        "\n",
        "    return data\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH9G-lWfIbTv"
      },
      "source": [
        "### From kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lm9nFbxOlTB8"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "api_token = {\"username\":\"siakesophie\",\"key\":\"760d5044c02669f464a1d97a873a4827\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPQJgXsVlfgH",
        "outputId": "53540165-f75b-4170-c35e-95d195999b0d"
      },
      "outputs": [],
      "source": [
        "# list datasets on kaggle with the name Ravdess\n",
        "!kaggle datasets list -s RAVDESS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNB8NxL9mzc7"
      },
      "outputs": [],
      "source": [
        "# Authenticate into Kaggle and download the required dataset then unzip it in the folder in which we are found\n",
        "\n",
        "import kaggle\n",
        "\n",
        "kaggle.api.authenticate()\n",
        "\n",
        "kaggle.api.dataset_download_files('uwrfkaggler/ravdess-emotional-speech-audio', path='.', unzip=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qdm-fcBGYpe"
      },
      "source": [
        "## Data Processing\n",
        "- Audio Normalization\n",
        "- Silence Removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsnJYdGqHD3N"
      },
      "outputs": [],
      "source": [
        "def normalize(X):\n",
        "    max_X = np.max(np.abs(X))\n",
        "    Y = X / max_X\n",
        "\n",
        "    return Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiPbwP4jHDY_"
      },
      "outputs": [],
      "source": [
        "def remove_silence(X, factor):\n",
        "    max_X = np.max(np.abs(X))\n",
        "    decision_threshold = max_X / factor\n",
        "\n",
        "    # Find the indices of samples above the decision threshold\n",
        "    indices_useful_X, _ = find_peaks(np.abs(X), height=decision_threshold)\n",
        "\n",
        "    # Extract the useful samples\n",
        "    Y = X[indices_useful_X[0]:indices_useful_X[-1] + 1]\n",
        "\n",
        "    return Y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "856qfyvJrizG"
      },
      "outputs": [],
      "source": [
        "def normalise_remove_silence(input_filename, output_directory, factor):\n",
        "    # Read the input audio file\n",
        "    x, fs = librosa.load(input_filename, sr=None)\n",
        "\n",
        "    # Normalize the audio\n",
        "    y = normalize(x)\n",
        "\n",
        "    # Remove silence\n",
        "    z = remove_silence(y, factor)\n",
        "\n",
        "    # Extract the filename and extension\n",
        "    filename, extension = os.path.splitext(os.path.basename(input_filename))\n",
        "\n",
        "    # Create the output filename in the specified directory\n",
        "    output_filename = os.path.join(output_directory, f\"{filename}_N_RS{factor}{extension}\")\n",
        "\n",
        "    # Write the processed audio to the output file\n",
        "    sf.write(output_filename, z, fs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x461Ay9HL3N"
      },
      "source": [
        "## Audio Feature Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwaE8Cnw4Ec_"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import mode\n",
        "\n",
        "def global_feature_computation(feature_matrix, computations):\n",
        "    computed_features = []\n",
        "    for computation in computations:\n",
        "        if computation == \"mean\":\n",
        "            computed_features.append(np.mean(feature_matrix, axis=1))\n",
        "        elif computation == \"min\":\n",
        "            computed_features.append(np.min(feature_matrix, axis=1))\n",
        "        elif computation == \"max\":\n",
        "            computed_features.append(np.max(feature_matrix, axis=1))\n",
        "        elif computation == \"std\":\n",
        "            computed_features.append(np.std(feature_matrix, axis=1))\n",
        "        elif computation == \"range\":\n",
        "            computed_features.append(np.ptp(feature_matrix, axis=1))\n",
        "        elif computation == \"mode\":\n",
        "            # Use scipy.stats.mode to get mode and count\n",
        "            mode_result = mode(feature_matrix, axis=1)\n",
        "            computed_features.append(mode_result.mode.flatten())\n",
        "        elif computation == \"median\":\n",
        "            computed_features.append(np.median(feature_matrix, axis=1))\n",
        "        elif computation == \"1st_quartile\":\n",
        "            computed_features.append(np.percentile(feature_matrix, 25, axis=1))\n",
        "        elif computation == \"3rd_quartile\":\n",
        "            computed_features.append(np.percentile(feature_matrix, 75, axis=1))\n",
        "        # Add conditions for other computations\n",
        "\n",
        "    return np.concatenate(computed_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDTlQUWwGMwh"
      },
      "outputs": [],
      "source": [
        "def extract_features(audio_path, features, global_computation):\n",
        "    # Load the normalized and silence-removed audio\n",
        "    audio, sr = librosa.load(audio_path)\n",
        "\n",
        "    lst_spectral_flatness = []\n",
        "    lst_spectral_centroid = []\n",
        "    lst_mfcc = []\n",
        "    lst_melspectrogram = []\n",
        "    lst_chroma_stft = []\n",
        "    lst_rms = []\n",
        "\n",
        "    feature_list = []\n",
        "\n",
        "    # Extract selected features\n",
        "    for feature_name in features:\n",
        "        if feature_name == \"spectral_flatness\":\n",
        "            spectral_flatness = librosa.feature.spectral_flatness(y=audio)\n",
        "            lst_spectral_flatness.append(global_feature_computation(spectral_flatness, global_computation))\n",
        "        elif feature_name == \"spectral_centroid\":\n",
        "            spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr = sr)\n",
        "            lst_spectral_centroid.append(global_feature_computation(spectral_centroid, global_computation))\n",
        "        elif feature_name == \"mfcc\":\n",
        "            mfcc = librosa.feature.mfcc(y=audio, sr = sr)\n",
        "            lst_mfcc.append(global_feature_computation(mfcc, global_computation))\n",
        "        elif feature_name == \"melspectrogram\":\n",
        "            mel_spectrum = librosa.feature.melspectrogram(y=audio, sr = sr)\n",
        "            lst_melspectrogram.append(global_feature_computation(mel_spectrum, global_computation))\n",
        "        elif feature_name == \"chroma_stft\":\n",
        "            chroma_stft = librosa.feature.chroma_stft(y=audio, sr = sr)\n",
        "            lst_chroma_stft.append(global_feature_computation(chroma_stft, global_computation))\n",
        "        elif feature_name == \"rms\":\n",
        "            rms = librosa.feature.rms(y=audio)\n",
        "            lst_rms.append(global_feature_computation(rms, global_computation))\n",
        "\n",
        "\n",
        "    feature_list.append(lst_spectral_flatness[0])\n",
        "    feature_list.append(lst_spectral_centroid[0])\n",
        "    feature_list.append(lst_mfcc[0])\n",
        "    feature_list.append(lst_melspectrogram[0])\n",
        "    feature_list.append(lst_chroma_stft[0])\n",
        "    feature_list.append(lst_rms[0])\n",
        "\n",
        "\n",
        "    # Combine the extracted features into a single feature vector\n",
        "    feature_vector = np.concatenate(feature_list)\n",
        "\n",
        "    return feature_vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lELnXZLGMwh"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OEvoQeJHTuM"
      },
      "source": [
        "## Model Training\n",
        "- SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1ESsHiRCvf5"
      },
      "outputs": [],
      "source": [
        "features = [\"spectral_flatness\", \"spectral_centroid\", \"mfcc\", \"chroma_stft\", \"melspectrogram\", \"rms\"]\n",
        "global_computation = [\"mean\"]\n",
        "#global_computation = [\"mean\", \"min\", \"max\", \"std\", \"range\", \"mode\", \"median\"]\n",
        "\n",
        "class_names = [\"Neutral\", \"Cal\", \"Happiness\", \"Sadness\", \"Angry\", \"Fear\", \"Disgust\", \"Surprise\"]\n",
        "\n",
        "factor = 200\n",
        "\n",
        "num_selected_features = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJs_JWYnJMRC"
      },
      "source": [
        "### Normalizing and removing the silence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-k4x5T1CXhl"
      },
      "outputs": [],
      "source": [
        "# Set the base directory where actor directories are located\n",
        "base_directory = '/content/audio_speech_actors_01-24'\n",
        "output_directory = '/content/processed_data'\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# First loop: Normalize and remove silence\n",
        "for actor_directory in os.listdir(base_directory):\n",
        "    actor_path = os.path.join(base_directory, actor_directory)\n",
        "\n",
        "    # Check if it's a directory\n",
        "    if os.path.isdir(actor_path):\n",
        "\n",
        "        # Iterate over audio files in the actor's directory\n",
        "        for audio_file in os.listdir(actor_path):\n",
        "            audio_path = os.path.join(actor_path, audio_file)\n",
        "\n",
        "            # Normalize and remove silence\n",
        "            normalise_remove_silence(audio_path, output_directory, factor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5Vo0jRWJJps"
      },
      "outputs": [],
      "source": [
        "# List to store the paths of normalized audio files\n",
        "normalized_audio_paths = []\n",
        "\n",
        "for audio_file in os.listdir(output_directory):\n",
        "    normalized_audio_path = os.path.join(output_directory, audio_file)\n",
        "\n",
        "    # Append to the list of normalized audio paths\n",
        "    normalized_audio_paths.append(normalized_audio_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1YrGP83J0-7"
      },
      "outputs": [],
      "source": [
        "# Initialize lists for audio files, labels, and features\n",
        "features_list = []\n",
        "audio_files = []\n",
        "\n",
        "for normalized_audio_path in normalized_audio_paths:\n",
        "    extracted_features = extract_features(normalized_audio_path, features, global_computation)\n",
        "\n",
        "    # Append to lists or perform further processing as needed\n",
        "    audio_files.append(normalized_audio_path)\n",
        "    features_list.append(extracted_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma06Q3jPTvPL"
      },
      "outputs": [],
      "source": [
        "# Convert features_list to a NumPy array if needed\n",
        "features_list = np.array(features_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvO6Qr65dgYm",
        "outputId": "4b2acc96-69e2-4393-ee53-3577169a5e41"
      },
      "outputs": [],
      "source": [
        "features_list.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyPugdT1ptV6"
      },
      "source": [
        "### labels\n",
        "Here is the filename identifiers as per the official RAVDESS website:\n",
        "\n",
        "- Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
        "- Vocal channel (01 = speech, 02 = song).\n",
        "- Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
        "- Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
        "- Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
        "- Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
        "- Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
        "\n",
        "\n",
        "So, here's an example of an audio filename. 02-01-06-01-02-01-12.mp4 This means the meta data for the audio file is:\n",
        "\n",
        "- Video-only (02)\n",
        "- Speech (01)\n",
        "- Fearful (06)\n",
        "- Normal intensity (01)\n",
        "- Statement \"dogs\" (02)\n",
        "- 1st Repetition (01)\n",
        "- 12th Actor (12) - Female (as the actor ID number is even)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EqQ9fUPpsto"
      },
      "outputs": [],
      "source": [
        "labels = []\n",
        "\n",
        "for actor_directory in os.listdir(base_directory):\n",
        "    actor_path = os.path.join(base_directory, actor_directory)\n",
        "\n",
        "     #Check if it's a directory\n",
        "    if os.path.isdir(actor_path):\n",
        "\n",
        "        # Iterate over audio files in the actor's directory\n",
        "        for audio_file in os.listdir(actor_path):\n",
        "            # Split the file name using the \"-\" delimiter and take the third part as the emotion label\n",
        "            parts = audio_file.split(\"-\")\n",
        "            emotion_label = parts[2]\n",
        "            labels.append(emotion_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzJGBcOnrhdB"
      },
      "outputs": [],
      "source": [
        "labels = np.array(labels)\n",
        "labels = labels.astype(np.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEWFQ0DLrSH_",
        "outputId": "586af70c-242d-4a38-eb28-414f4c58d869"
      },
      "outputs": [],
      "source": [
        "labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvZeMYNZKOnD"
      },
      "outputs": [],
      "source": [
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_list, labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6mMgE1UkYFh",
        "outputId": "a44221ea-ff22-4c7b-ca9d-e1c860d0fc02"
      },
      "outputs": [],
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "74WDB2gseUHP",
        "outputId": "759f8920-2f4a-4062-833b-a3a4d6db0952"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize and train the SVM model\n",
        "svc_model = SVC()\n",
        "svc_model.fit(X_train, y_train)\n",
        "#\n",
        "#\n",
        "# Initialize and train the KNN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train, y_train)\n",
        "#\n",
        "#\n",
        "# Initialize and train the Gradient Boosting model\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "#\n",
        "#\n",
        "# Standardize the data before training neural networks\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "#\n",
        "# Initialize and train the Neural Network model\n",
        "nn_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
        "nn_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEDMrrSrK6Vg"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred_svc = svc_model.predict(X_test)\n",
        "y_pred_knn = knn_model.predict(X_test)\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "y_pred_nn = nn_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJI5P260hW8S",
        "outputId": "2a2a6f98-a821-4672-dba6-7e30c7124e03"
      },
      "outputs": [],
      "source": [
        "y_pred_svc.shape, y_pred_knn.shape,  y_pred_gb.shape, y_pred_nn.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kp-McQsOgGFn"
      },
      "outputs": [],
      "source": [
        "# Accuracies\n",
        "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "accuracy_gb  = accuracy_score(y_test, y_pred_gb)\n",
        "accuracy_nn  = accuracy_score(y_test, y_pred_nn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fioUCxmgiIg"
      },
      "outputs": [],
      "source": [
        "models = []\n",
        "accuracies = []\n",
        "\n",
        "models.append(svc_model)\n",
        "models.append(knn_model)\n",
        "models.append(gb_model)\n",
        "models.append(nn_model)\n",
        "\n",
        "accuracies.append(accuracy_svc)\n",
        "accuracies.append(accuracy_knn)\n",
        "accuracies.append(accuracy_gb)\n",
        "accuracies.append(accuracy_nn)\n",
        "\n",
        "model_accuracy_df = pd.DataFrame(models, columns=['Models'])\n",
        "model_accuracy_df['Accuracies'] = accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "7qVgbqDXi2OV",
        "outputId": "20798447-3faa-48c9-d40c-52fbd3ec5747"
      },
      "outputs": [],
      "source": [
        "model_accuracy_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqWiAnkbZNbB",
        "outputId": "0abe1db0-b625-4a94-8a27-a5b2066d6448"
      },
      "outputs": [],
      "source": [
        "evaluate_model(svc_model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVnRkUQsZWbS",
        "outputId": "f89b8cae-cac8-4c14-bb62-73b662e103ad"
      },
      "outputs": [],
      "source": [
        "evaluate_model(knn_model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImMK-WmwZYbt",
        "outputId": "9dae976b-8d79-445b-c703-12dd2311bc13"
      },
      "outputs": [],
      "source": [
        "evaluate_model(gb_model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAH-qoZ1ZY4l",
        "outputId": "d918cff0-04eb-4b1a-9225-ecb2fb44cd0a"
      },
      "outputs": [],
      "source": [
        "evaluate_model(nn_model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4VXWFX4TZI4"
      },
      "source": [
        "## Training with DNN & CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWTCTvSxTYt9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model, Sequential\n",
        "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFDiInOpXVCa"
      },
      "outputs": [],
      "source": [
        "Y = []\n",
        "for i in range(labels.size):\n",
        "  Y.append(labels[i])\n",
        "  print(labels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "zbwLauNWLEE_",
        "outputId": "85121589-d5e6-482b-c2b6-ec47256f05f9"
      },
      "outputs": [],
      "source": [
        "# Reconstruction of the dataset with the lables from 01 to 07\n",
        "\n",
        "display(features_list.shape)\n",
        "df = pd.DataFrame(features_list)\n",
        "df['labels'] = Y\n",
        "df.to_csv('features.csv', index=False)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "_8agDCOaOGOk",
        "outputId": "a747df1f-a4ac-4cb1-b2b7-d7244f989e29"
      },
      "outputs": [],
      "source": [
        "df_norm = df.drop(\"labels\", axis=1)\n",
        "df_norm.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qnkNK-INh6m"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(df_norm)\n",
        "print(scaler.mean_)\n",
        "df_norm = scaler.transform(df_norm)\n",
        "\n",
        "df_norm = pd.DataFrame(df_norm)\n",
        "df_norm.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksBMLuWDQHj1"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_norm, labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXYasv_IZ1oL",
        "outputId": "e00b4d99-1093-4803-9b63-d3973b54b5f0"
      },
      "outputs": [],
      "source": [
        "# Let check the data shape\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBU7PyVHaZKG",
        "outputId": "3cbb20e9-042b-4a7f-882a-d2333824d2d9"
      },
      "outputs": [],
      "source": [
        "# For use the CNN model, let expand the data dimensions\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8QuPWzrar3s"
      },
      "outputs": [],
      "source": [
        "# Modeling\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Conv1D(128, kernel_size=5, strides = 1, padding='same', activation=tf.nn.relu, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation=tf.nn.relu))\n",
        "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=32, activation=tf.nn.relu))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(units=9, activation=tf.nn.softmax))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgtMexw0bE9D"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPrFCHZMbUey"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor  = \"val_accuracy\",\n",
        "                   mode     = 'max',\n",
        "                   verbose  = 0,\n",
        "                   patience = 30)\n",
        "mc = ModelCheckpoint('model_best.h5',\n",
        "                     monitor        = 'val_accuracy',\n",
        "                     mode           = 'max',\n",
        "                     verbose        = 1,\n",
        "                     save_best_only = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo1rt14Ra5KO",
        "outputId": "5425538b-b26b-4158-c025-eee5ea860ebf"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRmVz95abaTj",
        "outputId": "f4807836-23d5-4adc-c996-8a7220271134"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 100\n",
        "EPOCHS = 30\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1, callbacks=[es, mc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "pmdVnuAXg_mc",
        "outputId": "b7cdec49-395d-428e-eb85-2b2f03a357e2"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy of our model on test data : \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")\n",
        "\n",
        "epochs = [i for i in range(EPOCHS)]\n",
        "fig , ax = plt.subplots(1,2)\n",
        "train_acc = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "test_acc = history.history['val_accuracy']\n",
        "test_loss = history.history['val_loss']\n",
        "\n",
        "fig.set_size_inches(20,6)\n",
        "ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
        "ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n",
        "ax[0].set_title('Training & Testing Loss')\n",
        "ax[0].legend()\n",
        "ax[0].set_xlabel(\"Epochs\")\n",
        "\n",
        "ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
        "ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n",
        "ax[1].set_title('Training & Testing Accuracy')\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel(\"Epochs\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
